"Task ID","realization Of","Name","Related Technique","Order","Related Activity","Description","Source","Who","Input","Output","Tools"
"TA_NeOn_1","P103, P111, P112","Identify purpose, scope and level of formality","TE5","1","A42","The objective of this task is to obtain the main goal or aim of the ontology, its coverage and granularity. The degree of formality to be used to codify the ontology should be also identified. This degree of formality ranges from informal natural language to a rigorous formal language. Users, domain experts and the ontology development team carry out this task taking as input a set of ontological needs for obtaining the purpose, scope and level of formality of the ontology, using techniques as physical or virtual interviewers between them. The task output is the purpose, scope and level of formality of the ontology, which will be included in the corresponding slots of the OSRD template. ","NeOn D5.4.1","","INF12","INF1,INF2,INF3",""
"TA_NeOn_2","P104","Identify intended ontology users","TE5","2","A42","The goal of this task is to establish which are the main intended users of the ontology. Users, domain experts and the ontology development team carry out this task taking as input a set of ontological needs for identifying the intended users, using techniques as physical or virtual interviewers between them. The task output is a list with the intended users, which will be included in the corresponding slot of the OSRD template.","NeOn D5.4.1","","INF12","INF4",""
"TA_NeOn_3","P105","Identify intended uses","TE5","3","A42","The goal of this task is to obtain the main ontology intended uses, that is, in which kind of scenarios the ontology will be used. Users, domain experts and the ontology development team carry out this task taking as input a set of ontological needs for identifying the intended uses, using techniques as physical or virtual interviewers between them. The development of an ontology is motivated by scenarios related to the application that will use the ontology. The task output is a list of intended uses in the form of scenarios. Such scenarios describe a set of the ontology’s requirements that the ontology should satisfy after being formally implemented. The scenarios can be described in natural language or expressed in UML as use cases. The list of scenarios will be included in the corresponding slot of the OSRD template.","NeOn D5.4.1","","INF12","INF5",""
"TA_NeOn_4","P106","Identify requirements","TE5","4","A42","The goal of this task is to obtain the set of requirements or needs that the ontology should fulfill.
Users, domain experts and the ontology development team carry out this task taking as input a set
of ontological needs for identifying the ontology requirements, using techniques as writing the
requirements in natural language in the form of the so-called competency questions (CQs) and
tools as mind map tools, excel, and collaborative tools.
The output of this task is a list of competency questions written in Natural Language and a set of
answers for the CQs.
Different approaches for identifying competency questions can be applied, such as:
 Top-Down: Complex questions are decomposed in simple ones.
 Bottom-Up: Simple questions that are organised to form complex ones.
 Middle out: Mix approach between top-down and bottom-up. ","NeOn D5.4.1","","INF12","INF6,INF7","MindMap tools
Wiki tools"
"TA_NeOn_5","P107","Group requirements","TE5","5","A42","The goal of this task is to group the list of CQs into several categories. Users, domain experts and the ontology development team carry out this task taking as input the list of CQs written in natural language (obtained in task 4) for obtaining different groups of CQs, using techniques as Card Sorting, when the grouping is done manually, and Clustering NL sentences or Information Extraction when the grouping is done automatically; and using tools as MindMap Tools or Cicero Tool (for distributed teams).","NeOn D5.4.1","","INF6","INF8",""
"TA_NeOn_6","P108","Validate the set of requirements","TE5","6","A42","The goal of this task is to identify possible conflicts between CQs, missing CQs, and contradictions in CQs. Users and domain experts carry out this task taking as input the set of grouped CQs for deciding if such CQs are valid or not. The task output is a confirmation about the validity of the set of CQs.","NeOn D5.4.1","","INF11","INF9",""
"TA_NeOn_7","P109","Prioritize requirements","TE5","7","A42","The goal of this task is to give different levels of priority to the different groups of CQs, and within each group to the identified requirements (in the form of CQs). Users, domain experts and the ontology development team carry out this task taking as input the groups of CQs written in natural language (obtained in task 5) for obtaining the priorities for each group and for each CQs within a group. The task output is a set of priorities attached to each group of CQs and to each CQ in a group. Priorities in CQs will be used for planning the ontology development. This task is optional, but recommended. In fact, if no priorities are given to the groups of CQs, the ontology development will model all requirements at the same time.","NeOn D5.4.1","","INF8","INF10",""
"TA_NeOn_8","P110","Extract terminology and its frequency","TE5","8","A42","The goal of this task is to extract from the list of CQs a pre-glossary to be used in the conceptualization activity. The ontology development team carries out this task taking as input the list of identified CQs and their answers for obtaining a list of the most used terms in them, using terminology extraction techniques and tools supporting such techniques. From the requirements in form of competency questions, we extract the terminology (names, adjectives and verbs) that will be formally represented in the ontology by means of concepts, attributes and relations. From the answers to the CQs we extract the objects in the universe of discourse that will be represented as instances.","NeOn D5.4.1","","INF6,INF7","INF12",""
"TA_NeOn_9","P80","Lexical Entries Extraction","","","A71","The goal of this task is to extract the lexical entries of the non ontological resources. Software developers and ontology practitioners carry out this task taking as input the non ontological resources for extracting their lexical entries using terminology extraction tools.","NeOn D5.4.1","R1,R3","INF_NeOn_16","INF_NeOn_17",""
"TA_NeOn_10","P81","Non-ontological Precision Calculation","","","A71","The goal of this task is to calculate the precision of the non ontological resources. Software developers and ontology practitioners carry out this task, taking as input the lexical entries extracted for the non ontological resources and the Ontology Requirements Specification Document (ORSD) for compute the precision of the non ontological resources. Precision is a measure widely used in information retrieval [16]. It is defined as the proportion of retrieved material that is actually relevant. To adapt this measure into our context we need to define: {NORLexicalEntries} is the set of lexical entries extracted from the non ontological resource. {ORSDTerminology} is the set of identified terms included in the Ontology Requirements Specification Document (ORSD). Now we can define the precision, in our context, as the proportion of the lexical entries of the non ontological resource that are included in the identified terms of the ORSD over the lexical entries of the non ontological resource. This is expressed as follows: Precision = ({NORLexicalEntries} intersection {ORSDTerminology}/{NORLexicalEntries})","NeOn D5.4.1","R1,R3","INF_NeOn_14, INF_NeOn_17","INF_NeOn_18",""
"TA_NeOn_11","P82","Non-ontological Coverage Calculation","","","A71","The goal of this task is to calculate the coverage of the non ontological resources. Software developers and ontology practitioners carry out this task, taking as input the lexical entries extracted from the non ontological resources and the Ontology Requirements Specification Document (ORSD) for computing the coverage of the non ontological resources. Coverage is based on recall measure used information retrieval [16]. Recall is defined as the proportion of relevant material actually retrieved in answer to a search request. To adapt this measure into our context, we use the aforementioned definition of {NORLexicalEntries} and {ORSDTerminology}. In this context, coverage is the proportion of the identified terms of the ORSD that are included in the lexical entries of the non ontological resource over the identified terms of the ORSD. This is expressed as follows: Coverage = ({NORLexicalEntries} intersection {ORSDTerminology}/{ORSDTerminology})","NeOn D5.4.1","R1,R3","INF_NeOn_14, INF_NeOn_17","INF_NeOn_19",""
"TA_NeOn_12","P83","Non-ontological Consensus Evaluation","","","A71","The goal of this task is to evaluate the consensus of the non ontological resources. Consensus is a subjective and not quantifiable criterion. Domain experts carry out this task taking as input the non ontological resources for stating whether the non ontological resources contain already consensuated terminology by the community or not.","NeOn D5.4.1","R2","INF_NeOn_16","INF_NeOn_20",""
"TA_NeOn_13","P84","Non-ontological Assessment Table Creation","","","A71","The goal of this task is to create an assessment table of the non ontological resources. Software developers and ontology practitioners carry out this task, taking as input the non ontological resources with their respective values for precision, coverage and consensus criteria, for the construction of the assessment table. This table is shown in Table 12. In the first column we include the non ontological resources found. In the precision column we include the calculated precision value for each non ontological resource. In the coverage column we include the calculated coverage value for each non ontological resource. Finally,
in the consensus column we include the domain experts’ judgment whether the non
ontological resource has consensus by the community or not (Yes/No). ","NeOn D5.4.1","R1,R3","INF_NeOn_18, INF_NeOn_19, INF_NeOn_20, INF_NeOn_22","INF_NeOn_21",""
"TA_NeON_14","P85","Non-ontological Quality Criteria Extraction","","","A71","Within this activity we propose in this deliverable to include the quality of the non-ontological resource. Quality attributes include:  Well documentation of the non-ontological resources.  Lack of anomalies of the non-ontological resource, such redundancies or inconsistencies.  Reliability of the non-ontological resource, it means analysing whether we can trust in the resource or not.","NeOn D5.4.2","R1,R2,R3","INF_NeOn_16","INF_NeOn_22",""
"TA_NeOn_15","P88","Non-ontological Resource Documentation Gathering","","","A73","The goal of this task is to search and compile all the available documentation about the non ontological resource including purpose, components; data model and implementation details. Domain experts and the ontology development team carry out this activity, taking as input the non ontological resource, searching in the non ontological resource web site and in general purpose search engines, or requesting the documentation directly to the non
ontological resource author. ","NeOn D5.4.1","R1,R2 ","INF_NeOn_15","INF_NeOn_24",""
"TA_NeOn_16","P89","Non-ontological Resource Schema Extraction","","","A73","The goal of this task is to identify the non ontological resource schema including the conceptual components and their relationships. Domain experts and the ontology development team carry out this activity taking as input the non ontological resource and the documentation obtained in task 1. If the non ontological resource schema is not available in the documentation, the schema should be reconstructed manually or using a data modeling tool.","NeOn D5.4.1","R1,R2","INF_NeOn_15, INF_NeOn_24","INF_NeOn_25",""
"TA_NeOn_17","P90","Non-ontological Resource Data Model Extraction","","","A73","The goal of this task is to find out how the non ontological resource schema and its content are represented in the data model. Domain experts and the ontology development team carry out this activity taking as input the non ontological resource, the documentation and schema. If the non ontological resource data model is not available in the documentation, the data model should be reconstructed manually or using a data modeling tool.","NeOn D5.4.1","R1,R2","INF_NeOn_15, INF_NeOn_24, INF_NeOn_25","INF_NeOn_26",""
"TA_NeOn_18","P92","Non-ontological Resource Reengineering Pattern Search","","","A74","The goal of this task is to find out if there is any applicable pattern for reengineering non ontological resources useful to transform the non ontological resource into a conceptual model. The ontology development team carries out this activity taking as input the non ontological resource, the schema and data model. The search for a suitable pattern for reengineering non ontological resource should be done into the NeOn repository of patterns, according to the type of non ontological resource, the data model, and the transformation approach. The transformation approach, explained in section 6.2, refers to: 1) transforming the non ontological resource schema into an ontology schema and the non ontological resource data into instances of the ontology; and 2) transforming the non ontological resource data into an ontology schema.","NeOn D5.4.1","R1","INF_NeOn_15, INF_NeOn_25, INF_NeOn_26","INF_NeOn_27",""
"TA_NeOn_19","P93","Non-ontological Resource Reengineering Pattern Transformation","","","A74","The goal of this task is to apply the reengineering pattern obtained in task 4 to transform the non ontological resource into a conceptual model. If a suitable pattern for reengineering non ontological resource is found then the ontology development team creates the conceptual model from the non ontological resource following the procedure established in the pattern for reengineering","NeOn D5.4.1","R1","INF_NeOn_15, INF_NeOn_27","INF_NeOn_28",""
"TA_NeOn_20","P94","Non-ontological Resource Reengineering Ad-hoc Transformation","","","A74","The goal of this task is to establish an ad-hoc procedure to map the non ontological resource into a conceptual model, just in case a suitable pattern for reengineering was not found. The ontology development team carries out this task choosing a transformation approach and then building a procedure to carry out the chosen transformation. This ad-hoc procedure may be generalized to create a new pattern for reengineering non ontological resource.","NeOn D5.4.1","R1","INF_NeOn_15","INF_NeOn_28",""
"TA_NeOn_21","P95","Ontology Design Patterns Requirements Identification","","","A50","The objective of this task is to identify which requirement(s), from the ORSD, can be addressed by ontology design pattern reuse. In many cases different methods will be used for realizing different parts of the requirements, and not all requirements may have suitable patterns available. The first task is to decide what specific requirements to include in the following steps. This task may be integrated with, or done iteratively together with, the next task, which is to select available pattern catalogues. In case no patterns are available to solve a specific type of problem, then those requirements are probably not likely to be amenable by design patterns; instead they should be realized using alternative activities within the NeOn methodology. The selection of requirements may be based on the following (non-exhaustive) list of criteria:
 What requirements are not addressed within other activities yet?
 What requirements do not have trivial solutions? 
 What requirements can be associated with existing pattern types?
The first question addresses the organizational aspects of the works, which requirements are not
treated yet and require a solution to be developed. The second question addresses the fact that
patterns do not usually provide solutions to trivial problems, but represent best practices for solving
some commonly occurring, repetitive problems. For example creating a single OWL class is quite
trivial, and although there may exist a logical pattern solving this issue it is commonly supported as
a basic functionality in ontology design environment and tools, therefore applying a pattern-based
methodology would in this case introduce overhead and give no added benefit (over using any
graphical ontology editing tool). “Trivial” is a relative concept here, in addition to indicating very
small problems, it can also be related to the experience and skills of the developer. If a person is
highly experienced and skilled in a certain area, then he might find a problem trivial, i.e. he
immediately knows the correct solution to the problem. In this case using patterns again introduces
an unnecessary overhead. Requirements where it is not immediately obvious (subjectively) how to
represent those in a “good” way are generally ideal candidates for design pattern reuse. For
example, how to model an n-ary relation might not be trivial to an inexperienced ontology engineer,
in this case a content pattern could help. Finally, in order for the requirement to be solvable but
design pattern reuse there must at least be pattern types that solve the kind of problems posed by
the requirements (the presence of actual suitable patterns is discussed in the next task).
Requirements are included within the ORSD expressed as competency questions (CQs). Different
aspects of a CQ may be realized by different kinds of patterns. Below is a list of the available types
of OPs and the kinds of problems they are intended to solve (for details see D2.5.1 [67]):
 Correspondence OP – used for either re-engineering or mapping between ontologies.
 Presentation OP – used for naming of elements or for annotating ontologies.
 Reasoning OP – used for introducing certain reasoning capabilities.
 Lexico-syntactic OP – used for linking natural language and ontological elements.
 Structural OP – used for designing the logical structure of ontologies.
 Content OP – used for designing the content of ontologies.
Structural and content OPs are generally useful for most kinds of modeling problems, since they
address the realization of the CQs into ontology elements and axioms. Lexico-syntactic patterns
may additionally be useful if the ontology design team includes novice users (see method in D5.4.1
[80]) or if a text corpus is used as the basis for building the ontology. Presentation OPs are useful if
usability aspects of the ontology are deemed important, and correspondence OPs are relevant
when building ontology networks by creating mapping between ontologies or when re-engineering
other kinds of resources. Reasoning patterns define the kind of reasoning services needed to
provide certain types of information. When choosing the requirements to address with ontology
design pattern reuse, these available pattern types should be considered, and requirements
covered by one or more of these types may be selected. ","NeOn D5.4.2","R1","INF_NeOn_14","INF_NeOn_29, INF_NeOn_30",""
"TA_NeOn_22","P96","Ontology Design Patterns Identification","","","A50","The goal of this task is to identify as many patterns, or rather pattern catalogues, as possible that could help in solving the modelling issues proposed by the requirements selected in the previous task. Catalogues of OPs may be found both in the form of written documents, like D5.1.1 [82] and D2.5.1 [67], and online catalogues like the ontology design pattern portal5. The relevant pattern types of the chosen requirements, identified in the previous task, should guide the search of available pattern catalogues. Aspects to consider when collecting patterns are for example the following:
 Relevant pattern types. 
 Relevant problem domain.
 Pattern provenance and reliability.
An example illustrating the criteria above could be the problem of realising a CQ exposing an n-ary
relation in the fisheries domain, such as connecting an aquatic resource observation to the
observed resource, the time of the observation, and the measured parameters. Both logical and
content pattern may be relevant, as well as presentation patterns for increasing usability aspects.
The domain is fishery, whereas only general domain independent patterns and pattern for this
specific domain should be considered (not for example patterns from the financial domain). If this
ontology is to be part of a safety critical system, then only well-known patterns and proven bestpractices would be considered, while in a less safety critical case even pattern candidates (not yet
approved by the community) could be considered for inspiration. ","NeOn D5.4.2","R1","INF_NeOn_30","",""
"TA_NeOn_23","P97","Ontology Design Patterns Requirements Problem Division","","","A50","The goal of this task is to prepare the set of modeling problems posed by the requirements for matching to the set of available patterns. Pattern-based design is inherently a divide-and-conquer approach, since patterns are restricted and solve a specific problem. In order to match the problem to such small partial solutions and reuse them, the problem needs to be divided into manageable pieces. In addition the problem could be divided in order to let different groups or individuals solve different sub-problems, not all the design team may be working on the same parts of the problem throughout the development. This task could include transformations like writing CQs to represent requirements stated only in example scenario sentences if not already present in the ORSD, and grouping of similar CQs that may be solved together by one or more pattern types if not already present in the ORSD, etc. It is recommended that pattern types that may affect the overall organization of the ontology are treated first, while detailed patterns are treated later. For example, presentation patterns such as naming conventions should be treated at the beginning since this will minimize the refactoring needed when applying the pattern to the solution. Similarly, reasoning patterns and structural patterns in the form of architecture patterns are recommended at an early stage, also in this case to minimize later refactoring. Finally, when the problem has been transformed and divided, one such “manageable piece” (for example, a set of CQs treating a coherent part of the intended ontology and envisioned to be solvable by logical or content patterns) is selected as a starting point. The rest of the tasks may be carried our iteratively, so that each sub-problem is solved before the next one is addressed, or in parallel, so that the sub-problems are divided between groups of designers and all groups solve their specific sub-problems in parallel (all using the tasks specified).","NeOn D5.4.2","R1","INF_NeOn_29, 
INF_NeOn_30","",""
"TA_NeOn_24","P98","Ontology Design Patterns Problem Matching","","","A50","The goal of this task is to identify which patterns are able to solve which parts of the selected subproblem, if any. How this task is solved is, of course, highly dependent on the type of patterns that are used. The matching procedure will differ a lot between, for example, matching naming pattern or reasoning pattern compared to matching content patterns. This task is identified as one of the hardest tasks of the process, and it is also a key task for the success of the complete process. This makes it the primary candidate for future tool support, but at the moment very little tool support is available. The ontology design pattern portal provides some search functions for finding patterns in the catalogues, but no support for the actual matching. Forthcoming versions of the planned XD plug-in (supporting a specific method for reuse of in the first version mainly content OPs described further lather in this chapter) for the NeOn toolkit will provide more support for pattern-based design and also the matching task. Some simple guidelines may be provided for specific types of OPs (see typology in D2.5.1 [67]). In
the previous deliverable, D5.4.1 [80], the support for selecting structural and logical patterns based
on natural language and lexico-syntactic patterns was described. For matching naming and
annotation patterns usually a manual reading of the guidelines accompanying the patterns is enough, since these patterns are more like guidelines and propose for example naming
conventions (in these cases the selection and reuse of the patterns is the more challenging part).
For matching correspondence OPs, support is being developed in the field of ontology matching
(see for example [71]), but so far no general guidelines exist. Finally, also in the field of matching of
content patterns only a few supporting tools may be found, one being the OntoCase approach as
presented in [8], where suggestions for suitable content patterns are proposed base on ontology
matching, ranking and learning algorithms.
To summarize, there are no detailed general guidelines for matching a problem to a pattern at
present, even though this is a crucial task within the overall process. More specific guidelines have
to be tailored to each of the pattern types (as we shall do later in this chapter, for content patterns),
we can only propose two brief general suggestions for performing this task in order to assist the
matching:
 Identify the type of patterns that may be suitable for solving the problem (if not already
done in previous tasks) and match problem primarily to these kinds of patterns.
 Depending on the type of pattern, use the description of the intent of the pattern to match it
to the problem (for content patterns this would mean to match the competency questions it
intends to solve to the competency questions of the problem). ","NeOn D5.4.2","R1","","",""
"TA_NeOn_25","P99","Ontology Design Patterns Selection","","","A50","The goal of this task is to select a set of patterns to reuse based on the results of the matching done in the previous task. These results may be of varying kind, if a formal method or tool was used then the matching results may be in the form of ranking values of a set of patterns. In that case the selection may be done by setting a threshold value. Still, other things than the individual matching results may be useful to take into account, since there may be overlapping or alternative patterns so that it is perhaps not suitable to select all of them. If manual matching was performed this is a decision-making process, where the usefulness of the pattern is weighted against the overhead of reusing it (instead of for example constructing a new solution). In many cases however it will be sufficient to simply study which patterns cover some part of the problem area and decide to reuse all of them, then applying a manual conflict resolution method in case there are overlaps or other conflicts that arise later.","NeOn D5.4.2","R1","","",""
"TA_NeOn_26","P100","Ontology Design Patterns Selection Reuse","","","A50","The goal of this task is to reuse the selected patterns and compose them. How a pattern can be reused is of course again highly dependent on the pattern type. For example to reuse a reasoning pattern may involve to adapt the complete ontology for supporting this particular way of reasoning, as well as selecting a reasoning engine to perform the actual reasoning task. While reusing a content pattern may be to import it into an ontology file and specialise its elements and axioms. Also partial reuse of a pattern is possible, if not the complete pattern is needed or even appropriate. An important part of this task is the composition of patterns. It is rare that a single pattern can solve the complete problem we are trying to address, even if it is very small. In many cases two or more patterns will have to be combined, and this combination task is called pattern composition. Composition of content patterns would involve adding the union of the elements and axioms from the patterns to the resulting ontology, but additionally to connect the elements from different patterns using additional elements and axioms in order to ensure that the pattern really solves the problem (in case of content patterns this is to be able to answer the CQs posed). A certain amount of conflict resolution may be needed if patterns involve contradicting parts, but as stated above partial pattern reuse is also possible. At this stage however the focus is still on the partial selected problem intended to be solved, not on the complete solution for all the selected requirements. Integration of the complete solution is performed later in the process.","NeOn D5.4.2","R1","","",""
"TA_NeOn_27","P101","Ontology Design Patterns Selection Evaluation","","","A50","The goal of this task is to test the solution with respect to the selected partial problem at hand and to ensure that it really solves this problem in a correct way. As stated at the beginning a patternbased approach is inherently a divide-and-conquer approach, and this also leads to the possibility to test small and manageable pieces of the solution before finally integrating them into the complete solution. It does not replace the evaluations and revision of the complete solution, but these small “unit tests” are an important part of the process. If the result of the last step is a small ontology then the ontology may be evaluated and tested for example through adding instances and running unit tests and queries corresponding to the CQs of the problem. If the evaluation identifies some problems of the solution then these problems should be addressed in this task, before proceeding to the next. When the solution passed all tests, the iteration continues, by performing tasks 3-7 again on the next partial problem until all problems have been covered, or if the problems were solved in parallel by immediately integrating all solutions.","NeOn D5.4.2","R1","","",""
"TA_NeOn_28","P102","Ontology Design Patterns Integration","","","A50","The goal of this task is to integrate the solutions to the partial problems solved by the previous iterations, or by the parallel teams working on different sub-problems. If the division of the problem resulted in a large number of partial tasks the number of partial solutions will also be large and this process may be quite challenging. In practice this integration may be performed after each solution of a small partial problem, instead of at the end of the complete process. The choice of method may depend on the team organisation. If arger design teams work on sub-problems in parallel and integrate their solutions as soon as they finish, the task needs to be performed in a collaborative fashion (supported by collaboration tools like chats, message boards or argumentation tools like Cicero [27]). On the other hand, if only one team is working in an iterative fashion, this task is less collaborative and simply contains the task of integrating one more “piece” into the complete solution. Either way, integration of the solutions is a challenging problem, and may involve refactoring of the whole solution. So far, detailed guidelines of this process are still future work, although technical guidelines for integrating ontologies are of course present.","NeOn D5.4.2","R1","","",""
"TA_UPON_1","P111, P113","Determining domain of interest and scope","","",""," Circumscribing the domain of interest is a fundamental step [8], to focus on the appropriate fragment of reality to be modeled. If the  domain is large, two or more subdomains may also be determined.
As anticipated, in this work the domain addressed to validate the UPON methodology is eBusiness. Specifically, the eProcurement  subdomain, i.e., the business-to-business (B2B) purchasing and selling goods and services over the Internet [WR4], has been  addressed.
Defining the scope of the ontology consists in the identification of the most important concepts to be represented, with their  characteristics, thus pushing the refinement to the suitable granularity. To this end, a set of ontological commitments [9] is required,  bringing some part of the domain into focus at the (required and expected) expense of other parts that will be less represented or  neglected.
Following Guarino et al. [9], the ontological commitment can be seen as ‘‘a mapping between a language and something which can  be called an ontology’’. In this preliminary stage, it can be seen as a set of statements that allows one to identify a first set of terms as  representatives of ontology concepts.
Usually at this stage modelers have only a vague idea of the position that each concept will assume within the ontology, i.e., the  semantic interconnections between pairs of concepts. If necessary, each term can be informally annotated by DE for further  development during subsequent iterations.","UPON","","","INF_UPON_6,
INF_UPON_7",""
"TA_UPON_2","P103, P104","Defining business purpose","","","","The reason for having an ontology, its intended uses, and kinds of target users must be established. In the eProcurement application,  the goal of the ontology is to provide a better understanding of the domain of interest and to support a number of semantic services  for ontology users (i.e., clients and suppliers in the purchasing processes). In particular, three basic uses of the ontology can be  envisaged:

	* resource discovery and retrieval, e.g., for semantically enriched documents or web services;
	* ontology-based reconciliation of data messages exchanged between sender and receiver business actors in business transactions  [10];
	* ontology-based mediation of business processes belonging to two different business partners (e.g., the steps in a purchasing  activity).

","UPON","","","INF_UPON_8, 
INF_UPON_9",""
"TA_UPON_3","P114","Writing storyboards","","","","In this step the DE is asked to write a panel or series of panels of rough sketches outlining the sequence of the activities that take  place in a particular scenario. Storyboards (modeling contexts and situations in a narrative way) can be used in this activity. In particular, a storyboard is related to a particular scenario of  the realization of one or more business purposes. In the considered eProcurement application, a storyboard sounds as follows:

	* ‘‘The ACME manufacturer (client) sends a request for quotation (RFQ) to the EMCA provider (supplier). The supplier processes the  RFQ and sends back his quotation to the client. The client evaluates the quotation and, possibly, makes the purchase order (PO) that  is sent to the supplier. The supplier accepts the purchase order, fulfills it, delivers the goods, and sends the invoice to the client.  Finally, if the delivered goods correspond to the order, the client pays the invoice.’’

","UPON","R2","INF_UPON_8","INF_UPON_10",""
"TA_UPON_4","P115","Create Application Lexicon","","","","Creating the AL, by collecting the terminology from DE and application-specific documents. The storyboard is used to extract the  terminology. Then a preliminary version of the AL is built. This task can be supported by using some automatic tools to extract  knowledge from textual documents, such as OntoLearn [2], Text-To-Onto [WR12], or similar tools. In the eProcurement example, the  AL contains 212 terms, mainly extracted from documents representing the reference XML schemas of AIDIMA business documents.  An excerpt of the AL is reported in Table 1.","UPON","","INF_UPON_10","INF_UPON_3","OntoLearn, Text-To-Onto"
"TA_UPON_5","P106","Identifying Competency Questions UPON","","","","CQs are questions at a conceptual level1 an ontology must be able to answer [7]. They are essentially identified through interviews  with DEs and end-users brainstorming. The questions are used during the test workflow to evaluate the ontological commitments  that have been made and, more in general, the coverage (related to domain circumscription) and the depth (level of detail of the ontology to be built). According to the main objectives of an ontology, CQs can  be of two different kinds: oriented either to resource discovery and retrieval or to reconciliation (within a semantic interoperability  solution). Some examples of CQs in the eProcurement application are presented in Table 2.","UPON","","INF_UPON_1","INF_UPON_4",""
"TA_UPON_6","P105, P109","Identifying and Prioritizing Use-Cases UPON","","","","UPON proposes to address CQs by using use-case models. According to UML, a use-case model contains a number of use cases that  serve as a basis to specify the expected use of the ontology. This model is a result of an agreement among different users (i.e., who  will use the ontology for a business purpose) achieved with the support of ontology modelers. In the context of ontologies, use cases  correspond to knowledge paths through the ontology, to be followed for achieving business operations and answering CQs. Use  cases will be detailed during the analysis and design workflows; here, in the requirements workflow, they are identified and  prioritized. The result will help indicate which use cases should be addressed during early iterations, and which ones can be  postponed. An example of a use-case model with the corresponding CQis reported in Fig. 4.","UPON","","INF_UPON_4","INF_UPON_5, INF_UPON_11",""
"TA_UPON_7","P30","Acquiring domain resources and building Domain Lexicon (DL)","","","","The DL is built by gathering the terminology used in the domain of interest, mainly extracted by analyzing existing documental resources, such as reports, technical manuals, standards, glossaries, thesauri, legacy computational lexicons, and available ontologies. This step, like in the case of the AL, can be supported by automatic tools for text mining. This activity inherently adheres to the view of a linguistic ontology [11] in which concepts are anchored to textual descriptions, i.e. they have a counterpart in natural language. In our project, to build the eBusiness DL, an important role has been played by standards. The DEs considered the following eBusiness standards: ebXML [WR5], RosettaNET [WR6], and OAGIS [WR7]. The analysis of these standards allowed 2613 elements to be extracted (140 from ebXML, 1873 from RosettaNET, 600 from OAGIS)2; then a consistent filtering has been necessary. In fact, since many elements from these standards pertain to specific industry sectors (e.g., elements coming from RosettaNet mainly refer to the high-tech electronic industry), a first manual pruning was performed. Then terminological analysis was done against the corpus of documents of reference, to identify specific (frequently used in eProcurement) terms to be included in the DL. Furthermore, DEs decided to include in the DL, all the terms present in at least two standards. Other terms were included only after approval from a wider panel of experts. After this activity, the DL contained 114 terms (not considering synonyms). (An excerpt of the DL is reported in Table 3.) In a simplified vision, useful for our example, these 114 terms represent the core of the initial 2613 terms. Fig. 6 sketchily reports the composition of the DL, with respect to the originating resources.","UPON","","INF_UPON_3, INF_UPON_15, 
INF_UPON_16","INF_UPON_12",""
"TA_UPON_8","P116","Building Reference Lexicon","","","","The RL is built by selectively merging the AL (from application DEs) and the DL (from existing external resources). During the merge of the two lexicons, the terms are grouped into three major areas: one intersection area and two disjoint areas, application specific and domain specific (see Fig. 7). To build the RL the following ‘‘inclusion policy’’ is used: the RL should include all the terms coming from the intersection area and, after the users and DEs approval, some terms belonging to the disjoint areas. Therefore the intersection area will be extended, on the one hand, with domain terms, considered useful for a better specification of the application at hand, and, on the other hand, with a part of the remaining application terms that are considered relevant, even if not extensively used by other applications. The output is a RL. In the eProcurement application, it contains 139 terms.","UPON","","INF_UPON_3, 
INF_UPON_12","INF_UPON_13",""
"TA_UPON_9","P18","Modeling application scenario using UML","","","","The goal of this activity is to model the application scenario, adding to the use-case diagrams, drawn in the Requirements Workflow, the activity and class diagrams. UML diagrams represent a model of the application and will be used for the validation of the ontology. All classes, actors, and activities modeled in UML must have a corresponding concept in the ontology. In Fig. 8, three representative UML diagrams, drawn for the eProcurement application, are reported. Please note, in the Class Diagram (Fig. 8c), the use of the 5Objectb profile. UML profiles are used to properly categorize the terms, according to the OPAL ontology representation methodology [12] (see below).","UPON","","INF_UPON_5","INF_UPON_17, 
INF_UPON_18",""
"TA_UPON_10","P18","Building the reference glossary (RG)","","","","A first version of a glossary is built by using the RL and by adding informal definitions (i.e., natural language sentences) to the terms. In essence, the RL evolves into a reference glossary (Fig. 9) by associating one or more definitions to each term. The definitions should be selected from knowledgeable sources and agreed among DEs and users. An excerpt from the reference glossary for the AIDIMA eProcurement domain is reported in Table 4. In this application the reference glossary contains 139 glossary entries.","UPON","","INF_UPON_13","INF_UPON_14",""
"TA_UPON_11","","Modeling concepts","","","A77","Modeling concepts. Each concept is categorized by associating a ‘‘kind’’ to it. Here we adopt the categories proposed by OPAL. These  include the major ontological categories, according to proposals of top ontologies, such as [16], or meta-ontologies [8,10,14], and  they are deeply inspired by the primary modeling constructs of UML. OPAL organizes concepts in three primary and some  complementary categories. The primary categories are:
        * business actor: gathering active elements of a business domain, able to activate, perform, or monitor a business process. DEs, in  analyzing the reality, are asked to identify relevant actors that operate producing, updating or consuming business objects (BOs). In  the eProcurement example, 15 business actors have been identified (Table 5).
        * business object: an entity on which a business process operates. A business object document (BOD) is a further refinement of a BO  that represents a category of documents in the business domain. In the AIDIMA scenario 14 BODs, belonging to the client and the  supplier, have been identified (Table 6).
        * business process: a business activity or operation aimed at the satisfaction of a business goal, operating on a set of BOs (e.g.,  purchase order issuing, requesting quotation). It can be rather simple, with a limited duration in time, or complex, with parallel branches and phases3 that last for a long time span. In the eProcurement example 19  business processes have been identified (Table 7).
Having presented the primary concept categories of OPAL, we now introduce the complementary categories, necessary to complete  a rich ontological representation of the observed reality.

        * Message: A message represents the information exchanged during an interaction (e.g., request, response) between processes  (someone prefers to say ‘‘among actors’’, but we prefer to focus on the processes that need to exchange info). A message is  characterized by a content that is typically a BOD (e.g., a RFQ-message, carrying a request for quotation). In OPAL we adopted the FIPA [WR8] approach,  based on 23 message types, related to different kinds of communicative acts. Specifically, we selected 8 message kinds for which the  payload matches a BOD in the eProcurement ontology. Table 8 shows the 8 selected message kinds matched with their  corresponding BODs in the eProcurement application.
        * Attribute: Attributes characterize the information structure of a concept. In OPAL there are atomic attributes, modeling elementary  information (e.g., street name), and complex attributes, modeling structured information (e.g., address). Essentially, a complex  attribute is defined as an aggregation of lower level complex and/or atomic attributes. Table 9 reports the list of 83 attributes  identified in the eProcurement example.","UPON","","INF_UPON_14, 
INF_UPON_17, 
INF_UPON_18","",""
"TA_UPON_12","","Modeling concepts hierarchies and domain specific relationships","","","A77","At this stage, concepts are hierarchically organized and formal relations are introduced. A first step consists in organizing the  concepts in a taxonomic hierarchy according to the generalization (i.e., IsA) relation. To this end, three main approaches are known in the literature [17]: top-down (from general to particular), bottom-up (from particular to general) and middle-out (or combined). The combined approach  consists in finding first the salient concepts (typically placed in a middle area) and then generalizing and specializing them. This  approach is considered to be the most effective because concepts ‘‘in the middle’’ tend to be more informative about the domain.
The resulting taxonomy can be extended with other relations, i.e., part-of and domain-specific relationships. The outcome of this  step is a SN,4 that is represented according to UML class diagram, in particular using generalization (IsA), aggregation (part-of) and  association. Therefore the SN can be represented in a diagrammatic format (see Figs. 11 and 12 for examples). Finally, this workflow  eventually provides a diagrammatic representation of the ontology in the form of a set of UML class diagrams.","UPON","","INF_UPON_14, 
INF_UPON_17, 
INF_UPON_18","",""